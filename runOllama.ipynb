{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1W-5At0csUwfw5X51TR7MxXQZEUV99cn1","timestamp":1711679029366}],"gpuType":"T4","authorship_tag":"ABX9TyPJc1/fzF1/vRpAy6gOAijT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#아래 2개는 GPU 정보 불러오기 위해 필요함 (https://github.com/ollama/ollama/issues/758)\n","!sudo apt-get install -y pciutils\n","!nvidia-smi"],"metadata":{"id":"QflWHzGSP2i1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUK52AL7M_j3"},"outputs":[],"source":["# ollama 설치\n","!curl -fsSL https://ollama.com/install.sh | sh"]},{"cell_type":"code","source":["# ollama 구동(백그라운드).\n","# 만일 ollama 관련 명령어가 안 돌아가면 이 코드를 다시 실행해주세요\n","!nohup ollama serve &"],"metadata":{"id":"opXSgAOtR6e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ollama 구동 확인 (NAME, ID, SIZE, MODIFIED만 뜨면 정상)\n","!ollama list"],"metadata":{"id":"lIZlKrCzTNpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"uzR7YXQzQSqg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ngrok 설치\n","!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok"],"metadata":{"id":"hHCCc0riTJuz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["아래 둘 중 하나만 실행하세요!"],"metadata":{"id":"n8mTYrK0wpFo"}},{"cell_type":"code","source":["# 양자화된(Q4_K_M) OpenHermes-2.5를 모델로 사용\n","%cd /content/drive/MyDrive/LLMModels/OpenHermes\n","#ollama pull : ollama 서버에서 openhermes 다운로드\n","!ollama pull openhermes\n","!ollama create aiTownNPC -f ./Modelfile4AITownOpenHermes\n","!date"],"metadata":{"id":"ZfUbz_Z1fvq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 양자화된(Q4_K_M) Mistral 7B Instruct v0.2를 모델로 사용 (출처 : https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF)\n","%cd /content/drive/MyDrive/LLMModels/Mistral-7B-Instruct-v0.2\n","!ollama create aiTownNPCMistral -f ./Modelfile4AITownMistral\n","!date"],"metadata":{"id":"Ypey9WUlDNad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 설치가 완료되었는지 확인\n","!ollama list"],"metadata":{"id":"P31fgIfZTNMa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 테스트\n","!curl http://localhost:11434/api/generate -d '{\"model\": \"aiTownNPC\", \"prompt\": \"You are an android. Do you dream of electric sheep?\", \"stream\": false}'"],"metadata":{"id":"IfDdC3qdXphU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ngrok으로 터널링 시작 (authtoken과, domain(예시 : penguins-positive-papaya.ngrok-free.app) 을 적고 실행해주세요)\n","# 실행 중단시 ollama serve도 같이 멈추게 되므로, 다시 시작하려면 위쪽 ollama serve부분 먼저 실행하고, 다시 여기를 실행해주세요\n","!ngrok authtoken NGROK의AUTHTOKEN을여기에적어주세요\n","!ngrok http 11434 --domain NGROK에서발급받은도메인.app --host-header=\"localhost:11434\""],"metadata":{"id":"Zb5fb7OoaHZY"},"execution_count":null,"outputs":[]}]}